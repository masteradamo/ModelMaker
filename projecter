from nltk.corpus import wordnet as wn
from os import listdir
import numpy as np
from sklearn.decomposition import PCA
from collections import defaultdict as dd
import matplotlib.pyplot as plt
from matplotlib import patches as pat

fold = "/home/masteradamo/academy/models/Wikipedia/5x5/"
red = 2
vocab = ["google","vape","troll","spam","blog"]

fr = fold + "wordus.txt"
fv = fold + "vectors/"
fd = fold + "dimensions/"

rt = [x.split("::")[0] for x in open(fr,'r').readlines()]
tr = {rt[n]:str(n) for n in range(len(rt))}
vsize = len(listdir(fv))
print("DICTIONARIES BUILT AND VOCAB COUNTED")

def extracter():
    syns = wn.synsets(input("BASE WORD: "))
    if len(syns) > 0:
        print("SELECT THE NUMBER OF DESIRED DEFINITION:")
        for n in range(len(syns)):
            print(str(n) + " = " + syns[n].definition())
#        choice = [x.name() for x in syns[int(input("CHOICE: "))].lemmas()]
        choice = [x.name() for x in syns[int(input("CHOICE: "))].lemmas() if x.name() in tr and int(tr[x.name()]) < vsize]
        print("LEMMAS:",choice)
        return choice
    else:
        print("NOT IN WORDNET VOCABULARY")
        return extracter()

def spacer(choice):
    start = {x.split("::")[0]:float(x.split("::")[1]) for x in open(fv+tr[choice[0]]+".txt").readlines()}
    for word in choice[1:]:
#        print("WORD",word)
        cont = {x.split("::")[0]:(start[x.split("::")[0]]+float(x.split("::")[1])) for x in open(fv+tr[word]+".txt").readlines() if x.split("::")[0] in start}
        start = cont
    return([x[1] for x in sorted([(start[y],y) for y in start],reverse=True)])

def outer(space,choice,dims):
#    mat = {x:{y.split("::")[0]:float(y.split("::")[1]) for y in open(fv+tr[x]+".txt").readlines() if y.split("::")[0] in space} for x in vocab+choice}
    mat = {x:dd(float) for x in vocab}
#    mat["centroid"] = {x:(sum([mat[y][x] for y in choice])/len(choice)) for x in space}
    for item in mat:
        for tup in open(fv+tr[item]+".txt").readlines():
            mat[item][tup.split("::")[0]] = float(tup.split("::")[1])
    cat = {x:{y.split("::")[0]:float(y.split("::")[1]) for y in open(fv+tr[x]+".txt").readlines() if y.split("::")[0] in space} for x in choice}
    cent = [sum([cat[x][y] for x in choice])/len(choice) for y in space]
    full = [[mat[x][y] for y in space] for x in vocab]
    cnorm = np.sqrt(sum([x**2 for x in cent]))
    mnorm = [np.sqrt(sum([x**2 for x in y])) for y in full]
    coses = [sum([full[y][x]*cent[x] for x in range(len(cent))])/(mnorm[y]*cnorm) for y in range(len(full))]
    newcent = [np.sqrt((cnorm**2)/(red*np.sqrt(dims))) for x in range(red)]
    newpos = [[(coses[x]*np.sqrt(2))/2,np.sqrt(1-(((coses[x]*np.sqrt(2))/2)**2))] for x in range(len(coses))]
    newfull = [[y*mnorm[x] for y in newpos[x]] for x in range(len(newpos))]
    for n in range(len(vocab)):
        if n%2 == 1:
            newfull[n] = [newfull[n][1],newfull[n][0]]
        print(vocab[n],newfull[n])
    print("CENTROID",newcent)
    lim = max([a for b in newfull for a in b] + newcent) + 2
#    circ = plt.Circle((0,0), radius = lim-5)
    ax = plt.gca()
#    ax.add_patch(circ)
    circ = pat.Arc((0,0),(lim*2)-5,(lim*2)-5,angle=90,linewidth=2,fill=False,linestyle="dashed")
    ax.add_patch(circ)
    plt.scatter([newcent[0]],[newcent[1]],marker="o",color="b")
    plt.scatter([x[0] for x in newfull],[x[1] for x in newfull],marker="o",color="g")
#    plt.scatter([x[0] for x in newfull[::2]],[x[1] for x in newfull[::2]],marker="o",color="g")
#    plt.scatter([x[1] for x in newfull[1::2]],[x[0] for x in newfull[1::2]],marker="o",color="g")
#    lim = max([a for b in newfull for a in b] + newcent) + 2
    labeled = [[vocab[x]]+newfull[x] for x in range(len(newfull))]
    labeled.append(["CENTROID",newcent[0],newcent[1]])
    for a,b,c in labeled:
        plt.annotate(a,xy=(b,c),xytext=(10,10),textcoords="offset points",ha="right",va="bottom")
    plt.xlim(0,lim)
    plt.ylim(0,lim)
    plt.show()
#    full = [[mat[x][y] for y in space] for x in vocab]
#    cat = {x:{y.split("::")[0]:float(y.split("::")[1]) for y in open(fv+tr[x]+".txt").readlines() if y.split("::")[0] in space} for x in choice}
#    full.append([sum([cat[x][y] for x in choice])/len(choice) for y in space])
#    svd = PCA(red)
#    proj = svd.fit_transform(np.array(full))
#    for n in range(len(vocab)):
#        print(vocab[n],proj[n])
#    print("CENTROID",proj[-1])
#    norms = {x:np.sqrt(sum([(mat[x][y])**2 for y in space])) for x in vocab}
#    point = {x:(sum([mat[y][x] for y in choice])/len(choice)) for x in space}
#    ptnor = np.sqrt(sum([point[x]**2 for x in point]))
#    ratio = sum([np.sqrt(sum([mat[x][y] for y in space])) for x in choice])/len(choice)

while True:
    choice = extracter()
    dims = int(input("NUMBER OF DIMENSIONS: "))
    space = spacer(choice)[:dims]
    outer(space,choice,dims)
    print()
